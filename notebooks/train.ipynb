{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a89b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bebf28",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d9b96",
   "metadata": {},
   "source": [
    "Neste notebook iremos realizar o treinamento de um modelo de machine learning para que a partir dos dados de uma carta de God Unchained seja possível classificar sua estratégia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812d180",
   "metadata": {},
   "source": [
    "## Tabela de Conteúdo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c81069",
   "metadata": {},
   "source": [
    "1. [Feature Engineering](#feature_engineering)\n",
    "2. [Treinamento](#train)\n",
    "    * [Random Forest](#random_forest)\n",
    "    * [XGBoost](#xgboost)\n",
    "3. [Avaliação dos Modelos](#model_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a010ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60832a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"id\", \"name\", \"strategy\"], axis = 1)\n",
    "y = df[\"strategy\"].map({\"early\": 0, \"late\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e22d22",
   "metadata": {},
   "source": [
    "### Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b62028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_features_names(grid_search):\n",
    "    feature_names = grid_search.best_estimator_[0].get_feature_names()\n",
    "    selected_features_bool_index = grid_search.best_estimator_[1].get_support()\n",
    "    \n",
    "    features_dict = dict(zip(feature_names, selected_features_bool_index))\n",
    "    selected_features_names = [key for key, value in features_dict.items() if value]\n",
    "    \n",
    "    return selected_features_names\n",
    "\n",
    "def create_grid_search_report(grid_search_dict):\n",
    "    rows = []\n",
    "    for model_name, grid_search in grid_search_dict.items():\n",
    "        values = {\n",
    "            \"model_name\": model_name,\n",
    "            \"selected_features\": get_selected_features_names(grid_search),\n",
    "            \"best_score\": grid_search.best_score_,\n",
    "            \"best_params\": grid_search.best_params_\n",
    "        }\n",
    "        rows.append(values)\n",
    "        \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ff818",
   "metadata": {},
   "source": [
    "## Feature Engineering <a name=\"feature_engineering\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb1c8c3",
   "metadata": {},
   "source": [
    "O primeiro passo para realizarmos o treinamento do modelo é fazer o tratamento dos dados. Na etapa abaixo iremos transformar as váraveis categoricas **type** e **god** em colunas binárias utizando uma técnica chamada de **One Hot Encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39ba3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_column_transfomer = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"One Hot Encoder Type\", OneHotEncoder(), [3]),\n",
    "        (\"One Hot Encoder God\", OneHotEncoder(), [4]),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5791f0",
   "metadata": {},
   "source": [
    "## Treinamento <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f9847",
   "metadata": {},
   "source": [
    "O treinamento do nosso modelo será feito utilizando o Sklearn pipeline e irá possuir três etapas:\n",
    "* Pré-processamento\n",
    "* Feature Selection\n",
    "* Modelos\n",
    "\n",
    "E a partir do pipeline, rodaremos um **Grid Search** com a técnica de **Cross Validation**, pará escolher o modelo com melhores parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce594487",
   "metadata": {},
   "source": [
    "## Random Forest <a name=\"random_forest\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8daef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('One '\n",
       "                                                                         'Hot '\n",
       "                                                                         'Encoder '\n",
       "                                                                         'Type',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         [3]),\n",
       "                                                                        ('One '\n",
       "                                                                         'Hot '\n",
       "                                                                         'Encoder '\n",
       "                                                                         'God',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         [4])])),\n",
       "                                       ('feature_selection',\n",
       "                                        SelectFromModel(estimator=RandomForestClassifier())),\n",
       "                                       ('random_forest',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'random_forest__bootstrap': [True, False],\n",
       "                         'random_forest__max_depth': [10, 50],\n",
       "                         'random_forest__max_features': ['auto', 'sqrt'],\n",
       "                         'random_forest__min_samples_leaf': [1, 4],\n",
       "                         'random_forest__min_samples_split': [5, 10],\n",
       "                         'random_forest__n_estimators': [10, 100]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"preprocessing\", preprocess_column_transfomer),\n",
    "        (\"feature_selection\", SelectFromModel(random_forest_model)),\n",
    "        (\"random_forest\", random_forest_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "random_forest_grid_search = GridSearchCV(\n",
    "    random_forest_pipeline,\n",
    "    param_grid={\n",
    "        \"random_forest__bootstrap\": [True, False], \n",
    "        \"random_forest__n_estimators\": [10, 100],\n",
    "        \"random_forest__max_features\": ['auto', 'sqrt'],\n",
    "        \"random_forest__max_depth\": [10, 50],\n",
    "        \"random_forest__min_samples_split\": [5, 10],\n",
    "        \"random_forest__min_samples_leaf\": [1, 4]\n",
    "    },\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_forest_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd05cc",
   "metadata": {},
   "source": [
    "## XGBoost <a name=\"xgboost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7123774b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('One '\n",
       "                                                                         'Hot '\n",
       "                                                                         'Encoder '\n",
       "                                                                         'Type',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         [3]),\n",
       "                                                                        ('One '\n",
       "                                                                         'Hot '\n",
       "                                                                         'Encoder '\n",
       "                                                                         'God',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         [4])])),\n",
       "                                       ('feature_selection',\n",
       "                                        SelectFromModel(estimator=XGBClassifier(base_score=None,\n",
       "                                                                                booster=None,\n",
       "                                                                                colsample_bylevel=None,\n",
       "                                                                                colsample_bynode=None,...\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      random_state=None,\n",
       "                                                      reg_alpha=None,\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      use_label_encoder=False,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'xgboost__gamma': [1, 2, 5],\n",
       "                         'xgboost__max_depth': [3, 4, 5],\n",
       "                         'xgboost__min_child_weight': [1, 5, 10],\n",
       "                         'xgboost__subsample': [0.6, 0.8, 1.0]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgboost_pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"preprocessing\", preprocess_column_transfomer),\n",
    "        (\"feature_selection\", SelectFromModel(xgboost_model)),\n",
    "        (\"xgboost\", xgboost_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgboost_grid_search = GridSearchCV(\n",
    "    xgboost_pipeline,\n",
    "    param_grid = {\n",
    "        \"xgboost__min_child_weight\": [1, 5, 10], \n",
    "        \"xgboost__gamma\": [1, 2, 5],\n",
    "        \"xgboost__subsample\": [0.6, 0.8, 1.0],\n",
    "        \"xgboost__max_depth\": [3, 4, 5],\n",
    "    },\n",
    "    cv = 3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgboost_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f3818",
   "metadata": {},
   "source": [
    "## Avaliação dos Modelos <a name=\"model_evaluation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93de0ed",
   "metadata": {},
   "source": [
    "Para a avaliação dos modelos iremos utilizar a metrica chamada **Curva Roc**, que tem como principal objetivo medir a acertividade do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ad4701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>selected_features</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>[mana, attack, health]</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>{'random_forest__bootstrap': True, 'random_for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>[mana, attack, health]</td>\n",
       "      <td>0.998525</td>\n",
       "      <td>{'xgboost__gamma': 1, 'xgboost__max_depth': 4,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name       selected_features  best_score  \\\n",
       "0  random_forest  [mana, attack, health]    0.999102   \n",
       "1        xgboost  [mana, attack, health]    0.998525   \n",
       "\n",
       "                                         best_params  \n",
       "0  {'random_forest__bootstrap': True, 'random_for...  \n",
       "1  {'xgboost__gamma': 1, 'xgboost__max_depth': 4,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_grid_search_report({\n",
    "        \"random_forest\": random_forest_grid_search,\n",
    "        \"xgboost\": xgboost_grid_search\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964b80b",
   "metadata": {},
   "source": [
    "Como podemos ver o modelo que teve o melhor resultado foi a **Random Forest** com a **Curva Roc** de 0.99."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
